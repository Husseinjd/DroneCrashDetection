{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import pickle\n",
    "import sys\n",
    "from sklearn.neighbors import KNeighborsClassifier  \n",
    "import matplotlib.pyplot as plt\n",
    "import networkx as nx\n",
    "module_path = os.path.abspath(os.path.join('..'))\n",
    "if module_path not in sys.path:\n",
    "    sys.path.append(module_path)\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "import time\n",
    "from db.database import DatabaseConnector\n",
    "from dtloader.dataloader import DataLoader\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from statsmodels.tsa.stattools import grangercausalitytests\n",
    "module_path = os.path.abspath(os.path.join('..'))\n",
    "if module_path not in sys.path:\n",
    "    sys.path.append(module_path)\n",
    "from utils.utils import *\n",
    "import seaborn as sns\n",
    "from granger.grangercausality_reg import GrangerCausalityTest\n",
    "from granger.grangercausality_cl import GrangerCausalityDiscrete\n",
    "from segmentation.segmentation import *\n",
    "from statsmodels.tsa.stattools import adfuller\n",
    "from statsmodels.tsa.tsatools import lagmat2ds\n",
    "import statsmodels.api as sm\n",
    "from statsmodels.tools.tools import add_constant\n",
    "from utils.features_eng import *\n",
    "from scipy import stats\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from statsmodels.tsa.stattools import grangercausalitytests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mongodb://localhost:27017/\n",
      "Database connected\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\PC\\Desktop\\TUM Summer 2019\\Drone DC\\DroneCrashDetection\\dtloader\\dataloader.py:63: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  self.df[3] = self.df[3].str.strip() # cleaning third column\n"
     ]
    }
   ],
   "source": [
    "#connecting to the database \n",
    "dl = DataLoader()\n",
    "dl.load('../sample_testing/sample2.log')\n",
    "dl.extractinfo(export=False,single_file=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dl.dbconnector.query_str('sample2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>_id</th>\n",
       "      <th>TimeUS</th>\n",
       "      <th>Status</th>\n",
       "      <th>GMS</th>\n",
       "      <th>GWk</th>\n",
       "      <th>NSats</th>\n",
       "      <th>HDop</th>\n",
       "      <th>Lat</th>\n",
       "      <th>Lng</th>\n",
       "      <th>RAlt</th>\n",
       "      <th>Alt</th>\n",
       "      <th>Spd</th>\n",
       "      <th>GCrs</th>\n",
       "      <th>VZ</th>\n",
       "      <th>GPS_0</th>\n",
       "      <th>lineIndex</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5cfd4a85048d2b431094bd28</td>\n",
       "      <td>216191643</td>\n",
       "      <td>3</td>\n",
       "      <td>66089600</td>\n",
       "      <td>1950</td>\n",
       "      <td>7</td>\n",
       "      <td>1.28</td>\n",
       "      <td>56.590823</td>\n",
       "      <td>37.201885</td>\n",
       "      <td>0.00</td>\n",
       "      <td>123.81</td>\n",
       "      <td>0.11</td>\n",
       "      <td>328.3</td>\n",
       "      <td>-0.22</td>\n",
       "      <td>1</td>\n",
       "      <td>611</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5cfd4a85048d2b431094bd28</td>\n",
       "      <td>216212018</td>\n",
       "      <td>3</td>\n",
       "      <td>66090200</td>\n",
       "      <td>1950</td>\n",
       "      <td>7</td>\n",
       "      <td>1.28</td>\n",
       "      <td>56.590823</td>\n",
       "      <td>37.201885</td>\n",
       "      <td>0.00</td>\n",
       "      <td>123.81</td>\n",
       "      <td>0.03</td>\n",
       "      <td>328.3</td>\n",
       "      <td>-0.15</td>\n",
       "      <td>1</td>\n",
       "      <td>616</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5cfd4a85048d2b431094bd28</td>\n",
       "      <td>216271200</td>\n",
       "      <td>3</td>\n",
       "      <td>66090200</td>\n",
       "      <td>1950</td>\n",
       "      <td>7</td>\n",
       "      <td>1.28</td>\n",
       "      <td>56.590821</td>\n",
       "      <td>37.201886</td>\n",
       "      <td>0.01</td>\n",
       "      <td>124.23</td>\n",
       "      <td>0.06</td>\n",
       "      <td>328.3</td>\n",
       "      <td>0.03</td>\n",
       "      <td>1</td>\n",
       "      <td>621</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5cfd4a85048d2b431094bd28</td>\n",
       "      <td>216471200</td>\n",
       "      <td>3</td>\n",
       "      <td>66092200</td>\n",
       "      <td>1950</td>\n",
       "      <td>7</td>\n",
       "      <td>1.28</td>\n",
       "      <td>56.590821</td>\n",
       "      <td>37.201886</td>\n",
       "      <td>0.00</td>\n",
       "      <td>124.28</td>\n",
       "      <td>0.09</td>\n",
       "      <td>328.3</td>\n",
       "      <td>0.03</td>\n",
       "      <td>1</td>\n",
       "      <td>669</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5cfd4a85048d2b431094bd28</td>\n",
       "      <td>216671445</td>\n",
       "      <td>3</td>\n",
       "      <td>66092400</td>\n",
       "      <td>1950</td>\n",
       "      <td>7</td>\n",
       "      <td>1.28</td>\n",
       "      <td>56.590821</td>\n",
       "      <td>37.201886</td>\n",
       "      <td>-0.04</td>\n",
       "      <td>124.30</td>\n",
       "      <td>0.04</td>\n",
       "      <td>328.3</td>\n",
       "      <td>-0.10</td>\n",
       "      <td>1</td>\n",
       "      <td>719</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        _id     TimeUS  Status       GMS   GWk  NSats  HDop  \\\n",
       "0  5cfd4a85048d2b431094bd28  216191643       3  66089600  1950      7  1.28   \n",
       "1  5cfd4a85048d2b431094bd28  216212018       3  66090200  1950      7  1.28   \n",
       "2  5cfd4a85048d2b431094bd28  216271200       3  66090200  1950      7  1.28   \n",
       "3  5cfd4a85048d2b431094bd28  216471200       3  66092200  1950      7  1.28   \n",
       "4  5cfd4a85048d2b431094bd28  216671445       3  66092400  1950      7  1.28   \n",
       "\n",
       "         Lat        Lng  RAlt     Alt   Spd   GCrs    VZ  GPS_0  lineIndex  \n",
       "0  56.590823  37.201885  0.00  123.81  0.11  328.3 -0.22      1        611  \n",
       "1  56.590823  37.201885  0.00  123.81  0.03  328.3 -0.15      1        616  \n",
       "2  56.590821  37.201886  0.01  124.23  0.06  328.3  0.03      1        621  \n",
       "3  56.590821  37.201886  0.00  124.28  0.09  328.3  0.03      1        669  \n",
       "4  56.590821  37.201886 -0.04  124.30  0.04  328.3 -0.10      1        719  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(dl.dbconnector.query('GPS_sample_testing/sample2')).head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Granger Causality Sample Testing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For this test we need to put the two variables in one table with the line indexes and then test everything "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = 'CURR_Volt'\n",
    "y = 'ATT_Pitch'\n",
    "z = 'CTUN_ThrOut'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def signal_comp_va(signal_name):\n",
    "    return  signal_name[:signal_name.index('_')],signal_name[signal_name.index('_')+1:]\n",
    "\n",
    "def ft_eg(signal_name,sr,segmts,lag=5):\n",
    "    \"\"\"\n",
    "    given a continuous series return a dataframe with added features\n",
    "    methods are implemented in the file feature_eng.py in the utils directory\n",
    "    \"\"\"\n",
    "    seg_ratio = segment_ratio(sr, segmts)\n",
    "    seg_means = segment_mean(sr,segmts)\n",
    "    seg_ratio_perc = segment_ratio_outlier(seg_ratio)\n",
    "    moving_avg_data = moving_average_window(sr, 10)\n",
    "    lagged_segments = lagged_segment(sr, segmts) #lagged segment ratios\n",
    "    lagged_percentile = seg_ratio_perc.shift(lag).fillna(method='bfill')\n",
    "    lagged_seg_means = seg_means.shift(lag).fillna(method='bfill')\n",
    "    lagged_mov_avg = moving_avg_data.shift(lag).fillna(method='bfill')\n",
    "    \n",
    "    dataset = pd.DataFrame()\n",
    "    #dataset['seg_ratio'] = seg_ratio\n",
    "    #dataset['seg_ratio_percentile'] = seg_ratio_perc\n",
    "    #dataset[signal_name+' lagged_moving_avg'] = moving_avg_data\n",
    "    dataset[signal_name+' lagged_segments'] = lagged_segments\n",
    "    dataset[signal_name+' lagged_perc'] = lagged_percentile\n",
    "    dataset[signal_name+' lagged_means'] = lagged_seg_means\n",
    "    return dataset\n",
    "\n",
    "def segment_signal(comp,va,dl,filename):\n",
    "    \"\"\"\n",
    "    return a segment list of the signal\n",
    "    \"\"\"\n",
    "    sg = Segmentation(1)\n",
    "    fitmethod= 'inter'\n",
    "    sgmethod = 'td'\n",
    "    sr = dl.dbconnector.query(comp+'_' + filename,va)\n",
    "    sig_length = len(sr)\n",
    "    rng = dl.dbconnector.query(comp+'_'+filename,'lineIndex')\n",
    "    return sg.segment(sr,seg_method=sgmethod,fit_method=fitmethod,err_growth=0.2,batch=True,batch_size=50)\n",
    "\n",
    "\n",
    "def align_index(filename,comp_x,va_x,comp_z,va_z):\n",
    "    #aligning the time index of the two signals\n",
    "    #---------------------------------------------------------------------------\n",
    "    ts = {comp_x:[va_x],comp_z:[va_z]}\n",
    "    dft = corr_var(filename,dl,ts,find_corr=False)\n",
    "    dft.reset_index(inplace=True)\n",
    "    dft.drop('lineIndex',axis=1,inplace=True)\n",
    "    dft.dropna(axis=0,how='any',inplace=True) #remove nans\n",
    "    dft.index = range(len(dft))\n",
    "    #for variables with the same keys we add the other manaully    \n",
    "    #to be fixed later\n",
    "    if len(dft.columns) == 1:\n",
    "        #same key case - add the other to the dataframe\n",
    "        dft[comp_x+'_'+va_x] = dl.dbconnector.query(comp_x+'_'+filename,va_x)\n",
    "    return dft"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = 'sample_testing/sample2'\n",
    "\n",
    "\n",
    "def causality_cls_preprocess(filename, lag):\n",
    "    \"\"\"\n",
    "    preprocess data to put it in the write form for granger test using classification\n",
    "\n",
    "    :param filename : log file to process\n",
    "    :param lag: lag value for features \n",
    "\n",
    "    \"\"\"\n",
    "    # segmenting signals\n",
    "    # not loading from database to test different segments with max error and batch sizes\n",
    "    # ------------------------------------------------------------------------------------\n",
    "    # segment x\n",
    "    comp_x, va_x = signal_comp_va(x)\n",
    "    seg_x = segment_signal(comp_x, va_x, dl, filename)\n",
    "\n",
    "    # segment y\n",
    "    comp_y, va_y = signal_comp_va(y)\n",
    "    seg_y = segment_signal(comp_y, va_y, dl, filename)\n",
    "\n",
    "    # segment z\n",
    "    comp_z, va_z = signal_comp_va(z)\n",
    "    seg_z = segment_signal(comp_z, va_z, dl, filename)\n",
    "\n",
    "    # align time index between two files\n",
    "    dft = align_index(filename, comp_x, va_x, comp_z, va_z)\n",
    "    dft_y = align_index(filename, comp_y, va_y, comp_z, va_z)\n",
    "\n",
    "    # datasets containing the features for predictions\n",
    "    # Adding features\n",
    "    # ---------------------------------------------------------------------------\n",
    "    dataset_x = ft_eg(comp_x+'_'+va_x, dft[comp_x+'_'+va_x], seg_x, lag=lag)\n",
    "    dataset_y = ft_eg(comp_y+'_'+va_y, dft_y[comp_y+'_'+va_y], seg_y, lag=lag)\n",
    "    dataset_z = ft_eg(comp_z+'_'+va_z, dft[comp_z+'_'+va_z], seg_z, lag=lag)\n",
    "\n",
    "    # Building the target variable for z\n",
    "    # ---------------------------------------------------------------------------\n",
    "    seg_ratio_z = segment_ratio(dft[comp_z+'_'+va_z], seg_z)\n",
    "    target = np.zeros_like(seg_ratio_z)\n",
    "    threshold_event_occurred = -0.01  # Event = Massive  drop\n",
    "    idx = event_finder(seg_ratio_z, threshold_event_occurred, \"lesser\")\n",
    "    target[idx] = -1\n",
    "    threshold_event_occurred = 0.01  # Event = Massive  rise\n",
    "    idx = event_finder(seg_ratio_z, threshold_event_occurred, \"greater\")\n",
    "    target[idx] = 1\n",
    "    \n",
    "    \n",
    "    #if another variable was used the segments will not be equal to the lineindex concat so another must be constructed\n",
    "    seg_ratio_z = segment_ratio(dft_y[comp_z+'_'+va_z], seg_z)\n",
    "    target_y = np.zeros_like(seg_ratio_z)\n",
    "    threshold_event_occurred = -0.01  # Event = Massive  drop\n",
    "    idx = event_finder(seg_ratio_z, threshold_event_occurred, \"lesser\")\n",
    "    target_y[idx] = -1\n",
    "    threshold_event_occurred = 0.01 # Event = Massive  rise\n",
    "    idx = event_finder(seg_ratio_z, threshold_event_occurred, \"greater\")\n",
    "    target_y[idx] = 1\n",
    "\n",
    "    # combining features for full model\n",
    "    # ---------------------------------------------------------------------------\n",
    "    dataset_combined_xz = pd.concat([dataset_x, dataset_z], axis=1).dropna()\n",
    "    dataset_combined_yz = pd.concat([dataset_y, dataset_z], axis=1).dropna()\n",
    "    return dft, dft_y, dataset_x, dataset_y, dataset_z, dataset_combined_xz, dataset_combined_yz, target,target_y\n",
    "\n",
    "\n",
    "def test_causality(df, comp_x, va_x, dataset_red, dataset_combined, comp_z, va_z, target,cv):\n",
    "    l = ['nb', 'dt', 'knn', 'lr']\n",
    "    gcl = GrangerCausalityDiscrete(\n",
    "        names=[comp_x+'_'+va_x, comp_x+' +' + comp_z])\n",
    "    dict_cls = {}\n",
    "    for cls in l:\n",
    "        res = gcl.test(df[comp_x+'_'+va_x], df[comp_z+'_'+va_z], dataset_red, dataset_combined, target, check_stationary=False,\n",
    "                       classifier=cls, verbose=False, cv=cv)\n",
    "        dict_cls[cls] = {'Mean-Acc-Full': gcl.mean_full,\n",
    "                         'Mean-Acc-Reduced': gcl.mean_reduced, 'P-Value': gcl.pvalue}\n",
    "    return dict_cls"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# X Causes Z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\PC\\Desktop\\TUM Summer 2019\\Drone DC\\DroneCrashDetection\\segmentation\\segmentation.py:252: FutureWarning: `rcond` parameter will change to the default of machine precision times ``max(M, N)`` where M and N are the input matrix dimensions.\n",
      "To use the future default and silence this warning we advise to pass `rcond=None`, to keep using the old, explicitly pass `rcond=-1`.\n",
      "  (p,residuals,_,_) = lstsq(A,y)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Across Full Classifiers :  0.6041831366879853\n",
      "Mean Across Reduced Classifiers :  0.5824163871158087\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Mean-Acc-Full</th>\n",
       "      <th>Mean-Acc-Reduced</th>\n",
       "      <th>P-Value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>nb</th>\n",
       "      <td>0.680815</td>\n",
       "      <td>0.685005</td>\n",
       "      <td>0.990663</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dt</th>\n",
       "      <td>0.571788</td>\n",
       "      <td>0.511419</td>\n",
       "      <td>0.830310</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>knn</th>\n",
       "      <td>0.555579</td>\n",
       "      <td>0.567881</td>\n",
       "      <td>0.965744</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>lr</th>\n",
       "      <td>0.608550</td>\n",
       "      <td>0.565360</td>\n",
       "      <td>0.869024</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Mean-Acc-Full  Mean-Acc-Reduced   P-Value\n",
       "nb        0.680815          0.685005  0.990663\n",
       "dt        0.571788          0.511419  0.830310\n",
       "knn       0.555579          0.567881  0.965744\n",
       "lr        0.608550          0.565360  0.869024"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lag = 500\n",
    "cv = 2\n",
    "dft_x, dft_y, dataset_x, dataset_y, dataset_z, dataset_combined_xz, dataset_combined_yz, target_x, target_y = causality_cls_preprocess(\n",
    "    filename, lag)\n",
    "comp_y, va_y = signal_comp_va(y)\n",
    "comp_z, va_z = signal_comp_va(z)\n",
    "comp_x, va_x = signal_comp_va(x)\n",
    "\n",
    "\n",
    "dict_cls =  test_causality(dft_x,comp_x,va_x,dataset_z,dataset_combined_xz,comp_z,va_z,target_x,cv=cv)\n",
    "resdf = pd.DataFrame(dict_cls).T\n",
    "print('Mean Across Full Classifiers : ',resdf['Mean-Acc-Full'].mean())\n",
    "print('Mean Across Reduced Classifiers : ',resdf['Mean-Acc-Reduced'].mean())\n",
    "resdf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Y Causes Z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Across Full Classifiers :  0.5754969271413397\n",
      "Mean Across Reduced Classifiers :  0.5824163871158087\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Mean-Acc-Full</th>\n",
       "      <th>Mean-Acc-Reduced</th>\n",
       "      <th>P-Value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>nb</th>\n",
       "      <td>0.649082</td>\n",
       "      <td>0.685005</td>\n",
       "      <td>0.910034</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dt</th>\n",
       "      <td>0.511419</td>\n",
       "      <td>0.511419</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>knn</th>\n",
       "      <td>0.569838</td>\n",
       "      <td>0.567881</td>\n",
       "      <td>0.994816</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>lr</th>\n",
       "      <td>0.571649</td>\n",
       "      <td>0.565360</td>\n",
       "      <td>0.979004</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Mean-Acc-Full  Mean-Acc-Reduced   P-Value\n",
       "nb        0.649082          0.685005  0.910034\n",
       "dt        0.511419          0.511419  1.000000\n",
       "knn       0.569838          0.567881  0.994816\n",
       "lr        0.571649          0.565360  0.979004"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dict_cls =  test_causality(dft_y,comp_y,va_y,dataset_z,dataset_combined_yz,comp_z,va_z,target_y,cv=cv)\n",
    "resdf = pd.DataFrame(dict_cls).T\n",
    "print('Mean Across Full Classifiers : ',resdf['Mean-Acc-Full'].mean())\n",
    "print('Mean Across Reduced Classifiers : ',resdf['Mean-Acc-Reduced'].mean())\n",
    "resdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# d = pd.DataFrame()\n",
    "# comp_x, va_x = signal_comp_va(x)\n",
    "# comp_y, va_y = signal_comp_va(y)\n",
    "# d[y] = dl.dbconnector.query(comp_y+'_sample_testing/sample2',va_y)\n",
    "# d[z] = dl.dbconnector.query(comp_z+'_sample_testing/sample2',va_z)\n",
    "# grangercausalitytests(np.array(d),maxlag=10,verbose=1)[10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Testing on datasets\n",
    "clf = DecisionTreeClassifier(max_depth=6)\n",
    "scores_red= cross_val_score(clf,dataset_z,target_x, cv=cv,scoring='accuracy')\n",
    "scores_full= cross_val_score(clf,dataset_combined_xz,target_x, cv=cv,scoring='accuracy')\n",
    "print('full',np.mean(scores_full))\n",
    "print('red',np.mean(scores_red))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_z.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_combined_xz.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
